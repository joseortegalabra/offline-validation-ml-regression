{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "af23f723-2476-48da-8e1b-b5db90e9c3e6",
   "metadata": {},
   "source": [
    "# Plots predictions\n",
    "Plots of predictions of the models with any kind of transformation\n",
    "\n",
    "**IMPORTANT**: The list of models to evaluate is the same, but each model could have its own feature eng, but the Input (the data_X) and the Output (the prediction) follow the same structure, so it is necesary only one notebook to evaluate the differents notebooks of training (if it is not logic for you thinking in the kaggle competitions).\n",
    "\n",
    "In this notebook, there are a parameter \"folder_models\" and in this folder are located the pkl of each model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15086bcf-d1a7-4eda-9774-34444f24f03d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# fix root path to save outputs\n",
    "actual_path = os.path.abspath(os.getcwd())\n",
    "list_root_path = actual_path.split('\\\\')[:-1]\n",
    "root_path = '\\\\'.join(list_root_path)\n",
    "os.chdir(root_path)\n",
    "print('root path: ', root_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79d31f4e-c776-4d9d-8efe-055ef94e1edc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "375f572f-cfd4-4e8e-a895-580672796d41",
   "metadata": {},
   "source": [
    "## RUN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2c9c46b-0d53-4030-a0d8-55beed0ad1dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import plotly.graph_objs as go\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e047b73-7c55-477c-a028-bfea0c567c87",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d80e6679-8838-49be-aa44-f6393a2189a0",
   "metadata": {},
   "source": [
    "### 0. Global params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c807f7f-fe2e-40a3-9182-732d9ad5a3c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define folder where the models were saved. There are the same models accepted by gurobi but the feature eng changed\n",
    "\n",
    "# list of folder with models = ['basic', 'scaler', 'poly_2', 'poly_3']\n",
    "folder_models = 'poly_3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac559f84-4c10-4ebb-be4a-ba9440054d7f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8f383b70-f1d9-4606-86d1-91f166caa58b",
   "metadata": {},
   "source": [
    "### 1. Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b7fed6c-92db-4682-822e-8d95392568ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "### DEFINE LIST FEARTURES - TARGET (order data to have the same order in the features always)\n",
    "list_features = ['AveOccup', 'Latitude', 'Population', 'AveBedrms', 'HouseAge', 'Longitude', 'AveRooms', 'MedInc']\n",
    "target = 'Price'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f30e7496-7868-4436-b443-cdc415cbe977",
   "metadata": {},
   "outputs": [],
   "source": [
    "### LOAD DATA\n",
    "X_train = pd.read_pickle('artifacts/data/X_train.pkl')\n",
    "X_test = pd.read_pickle('artifacts/data/X_test.pkl')\n",
    "y_train = pd.read_pickle('artifacts/data/y_train.pkl')\n",
    "y_test = pd.read_pickle('artifacts/data/y_test.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aab84813-d0cf-4984-b985-0ee7d96ff227",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('shape data')\n",
    "print('\\n\\n TRAIN')\n",
    "print('X_train: ', X_train.shape)\n",
    "print('y_train: ', y_train.shape)\n",
    "\n",
    "print('\\n\\n TEST')\n",
    "print('X_test: ', X_test.shape)\n",
    "print('y_test: ', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d17ea9b7-8585-4830-a87d-c7fcdce765ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample - run fast\n",
    "X_train = X_train[0:100]\n",
    "y_train = y_train[0:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99bb083c-d2e2-4e10-97c3-84a8d4858836",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82a62564-70a5-4f91-9e38-1541fc78e9a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "51ef807b-a0a1-46c7-a9ad-65b023652cd3",
   "metadata": {},
   "source": [
    "### 2. Load Models\n",
    "Load all the models in a dictory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07259b0d-3fb9-4421-b230-bb4fecc999af",
   "metadata": {},
   "outputs": [],
   "source": [
    "## define list of models - list to have always the same order.\n",
    "#### In this example, the strings in the list are the same with the models were saved\n",
    "list_models_names = [\n",
    "    \"lr\",\n",
    "    \"ridge\",\n",
    "    \"lasso\",\n",
    "    \n",
    "    \"tree_simple\",\n",
    "    \"tree_default\",\n",
    "    \n",
    "    \"rf_simple\",\n",
    "    \"rf_default\",\n",
    "\n",
    "    \"gb_simple\",\n",
    "    \"gb_default\",\n",
    "\n",
    "    \"xgb_simple\",\n",
    "    \"xgb_default\",\n",
    "\n",
    "    \"mlp_simple\",\n",
    "    \"mlp_default\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e52f3b5-49b7-4b23-879c-b7b40fd96d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define path to folder models\n",
    "path_folder_models = f'artifacts/models/{folder_models}/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e53325c9-dfa6-4bbf-986c-db8cbd6fefcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "### load models\n",
    "dict_models = {}\n",
    "for model_name in list_models_names:\n",
    "    print(f'loading model: {model_name}')\n",
    "    path_model = path_folder_models + f'{model_name}.pkl'\n",
    "    with open(path_model, 'rb') as artifact:\n",
    "        dict_models[model_name] = pickle.load(artifact)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "563b03ad-9ea3-4867-8c49-52a71d60bd5c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7b50a035-6859-42a6-a00e-30b8d7492157",
   "metadata": {},
   "source": [
    "### 3. Hist Errors y_true vs y_pred (individual plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94379e09-1f62-4a05-82e3-292bf8235e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hist_errors_predictions(y, y_pred, title_plot, n_bins = 10):\n",
    "    \"\"\"\n",
    "    Plot histogram of error in prediction: errors: abs(y_true vs y_pred) (using matplotlib figure)\n",
    "\n",
    "    Args:\n",
    "        y (dataframe): dataframe with y-true values \n",
    "        y_pred (dataframe): dataframe with y-pred values\n",
    "        title_plot (string): tittle in the plot\n",
    "        n_bins (integer): number of bins in the histogram. Default = 10\n",
    "    \n",
    "    Return\n",
    "        fig (figure matplolib): figure to show, download, etc\n",
    "    \"\"\"\n",
    "    # calculate error\n",
    "    errors = y - y_pred\n",
    "    errors = np.abs(errors) # error in abs value\n",
    "    \n",
    "    # hist error\n",
    "    fig = plt.figure()\n",
    "    plt.hist(errors, bins = n_bins)\n",
    "    plt.xlabel('Error')\n",
    "    plt.ylabel('Freq')\n",
    "    plt.title(f'Histogram of Errors in Predictions:  abs(y - y_pred) - {title_plot}')\n",
    "\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25b76a6e-3b13-4c78-ae31-125409edd681",
   "metadata": {},
   "outputs": [],
   "source": [
    "# example\n",
    "\n",
    "model_example = dict_models['lr']\n",
    "y_example_true = y_train\n",
    "y_example_pred = model_example.predict(X_train)\n",
    "y_example_pred = pd.DataFrame(y_example_pred, index = y_example_true.index, columns = y_example_true.columns)\n",
    "\n",
    "# plot\n",
    "fig_example = hist_errors_predictions(y = y_example_true, \n",
    "                                        y_pred = y_example_pred, \n",
    "                                        title_plot = 'train - linear regression'\n",
    "                                   )\n",
    "\n",
    "# save plot\n",
    "fig_example.savefig(f'artifacts/plots_predictions_true_pred/{folder_models}/hist_errors_train_lr.png', dpi = 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bea2aab9-1d06-4c39-8154-711127d0b5ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "45a971ca-4a26-4071-82eb-f84064c38d5f",
   "metadata": {},
   "source": [
    "### 4. Hist Errors y_true vs y_pred (multiple plots - one plot for model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10dd0b19-a130-4e38-a95c-9df1edd5c60d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_errors_predictions_subplots_models(dict_models, X, y, n_bins = 10):\n",
    "    \"\"\"\n",
    "    Plot y_true vs y_pred for each model saved in dict_models (following the estrcture of a dictionary with differents models)\n",
    "\n",
    "    Args:\n",
    "        dict_models(dictionary): python dictionary where each element are differents models\n",
    "        X (dataframe): dataframe with features\n",
    "        y (dataframe): dataframe with target (y_true)\n",
    "        n_bins (integer): number of bins in the histogram. Default = 10\n",
    "    \n",
    "    Return\n",
    "        fig (figure matplolib): figure to show, download, etc\n",
    "    \"\"\"\n",
    "    # create subplots\n",
    "    number_models = len(dict_models)\n",
    "    fig, ax = plt.subplots(number_models, 1, figsize = ((10, 70)) , dpi = 300)\n",
    "    \n",
    "    for index, model_name in enumerate(dict_models):\n",
    "        \n",
    "        # calculate y_pred\n",
    "        y_pred = dict_models[model_name].predict(X)\n",
    "        y_pred = pd.DataFrame(y_pred, index = y.index, columns = y.columns)\n",
    "\n",
    "        # calculate error\n",
    "        errors = y - y_pred\n",
    "        errors = np.abs(errors) # error in abs value\n",
    "        \n",
    "        # plot scatter plot y_true vs y_pred\n",
    "        ax[index].hist(errors, bins = n_bins)\n",
    "\n",
    "        # Add names to axis\n",
    "        ax[index].set_xlabel('Error')\n",
    "        ax[index].set_ylabel('Freq')\n",
    "\n",
    "        # layout\n",
    "        ax[index].set_title(f'Hist Errors - Model: {model_name}')\n",
    "\n",
    "\n",
    "    # Adjust vertical spacing between subplots\n",
    "    fig.subplots_adjust(wspace=0.5)\n",
    "    \n",
    "    # Automatically adjust layout to avoid overlapping elements\n",
    "    plt.tight_layout()\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6062e93b-3ef5-4c0a-80d0-7c80455c4bf2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# generate plots data TRAIN\n",
    "fig_true_pred_models_train = plot_errors_predictions_subplots_models(dict_models = dict_models, \n",
    "                                                                   X = X_train, \n",
    "                                                                   y = y_train\n",
    "                                                                  )\n",
    "\n",
    "# save plot\n",
    "fig_true_pred_models_train.savefig(f'artifacts/plots_predictions_true_pred/{folder_models}/hist_errors_models_train.png', dpi = 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "161eab8d-03a2-4c1d-891f-20a6ebbd8848",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate plots data TEST\n",
    "fig_true_pred_models_test = plot_errors_predictions_subplots_models(dict_models = dict_models, \n",
    "                                                                   X = X_test, \n",
    "                                                                   y = y_test\n",
    "                                                                  )\n",
    "\n",
    "# save plot\n",
    "fig_true_pred_models_test.savefig(f'artifacts/plots_predictions_true_pred/{folder_models}/hist_errors_models_test.png', dpi = 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dda3c18f-1b9f-4233-81e0-9d5725425831",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb74e4ce-f812-4fa4-a35b-ec22f3100f56",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2400ca95-ed64-4dbf-abb6-2c0ffe14e06e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "549eeb3a-1c40-4975-958b-8461cc543360",
   "metadata": {},
   "source": [
    "### TODO: make this plots in plotly"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8c029b8-7e77-46df-8a2a-c412521dbc70",
   "metadata": {},
   "source": [
    "### 5. Plot errors ALL MODELS together\n",
    "This plot is made with plotly to interact with it (activate, deactivate plots for example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da18f93c-1299-4a51-9443-0f88ff463f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_errors_predictions_together(dict_models, X, y):\n",
    "    \"\"\"\n",
    "    Plot in plotly y_true vs y_pred for each model, all plots together in one only plot to interact with it\n",
    "    \n",
    "    Args:\n",
    "        dict_models(dictionary): python dictionary where each element are differents models\n",
    "        X (dataframe): dataframe with features\n",
    "        y (dataframe): dataframe with target (y_true)\n",
    "    \n",
    "    Return\n",
    "        fig (figure plotly): fig of plotly with the plot generated \n",
    "    \"\"\"\n",
    "    # generate dataframe with y_true, y_pred, model\n",
    "    df_error = pd.DataFrame()\n",
    "    for model_name, model in dict_models.items():\n",
    "        # calculate y_pred\n",
    "        y_pred = model.predict(X)\n",
    "        y_pred = pd.DataFrame(y_pred, index = y.index, columns = y.columns)\n",
    "\n",
    "        # calculate error\n",
    "        errors = y - y_pred\n",
    "        errors = np.abs(errors) # error in abs value\n",
    "\n",
    "        # save dataframe\n",
    "        df_error_aux = pd.DataFrame({'error': errors.values.flatten(), 'Model': model_name})\n",
    "        df_error = pd.concat([df_error, df_error_aux], ignore_index=True)\n",
    "    \n",
    "\n",
    "    # plot scatter plot - y_true vs y_pred\n",
    "    fig = px.histogram(df_error, color='Model', title='Errors abs(y_true - y_pred) by Model')\n",
    "    \n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92ad8c18-73f6-4a42-8360-39f517cb0845",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLOT DATA TRAIN\n",
    "fig_true_pred_all_models_train = plot_errors_predictions_together(dict_models = dict_models, \n",
    "                                                                       X = X_train, \n",
    "                                                                       y = y_train\n",
    "                                                                      )\n",
    "\n",
    "# show\n",
    "#fig_true_pred_all_models_train\n",
    "\n",
    "# save\n",
    "fig_true_pred_all_models_train.write_html(f'artifacts/plots_predictions_true_pred/{folder_models}/hist_errors_all_models_train.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f20b568-96fd-44f2-bb2b-e2072c86c3ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLOT DATA TEST\n",
    "fig_true_pred_all_models_test = plot_errors_predictions_together(dict_models = dict_models, \n",
    "                                                                       X = X_test, \n",
    "                                                                       y = y_test\n",
    "                                                                      )\n",
    "\n",
    "# show\n",
    "fig_true_pred_all_models_test.show()\n",
    "\n",
    "# save\n",
    "fig_true_pred_all_models_test.write_html(f'artifacts/plots_predictions_true_pred/{folder_models}/hist_errors_all_models_test.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8e479d0-5137-4b1c-af87-3dc989437352",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3375be6-b244-4b31-ad0b-757400a7dba9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b76db9e5-f616-4dad-b5c7-c049b6f30ac8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
